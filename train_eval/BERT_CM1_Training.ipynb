{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_CM1_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70e2c68cbaf040ed83605cf54f6c26dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b0c75620a3d4a758b69a3694e906b34",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cafb691fbb44af9b09521f617c7e903",
              "IPY_MODEL_ce30792bbd814748810e781815ea4d9c",
              "IPY_MODEL_c6c3dbb6290b42e2b4f9d2ea3437146a"
            ]
          }
        },
        "3b0c75620a3d4a758b69a3694e906b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cafb691fbb44af9b09521f617c7e903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2b781f13ee54fa7b9923d733f44a5da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d49bca4c481d473dbcad54ef4776f716"
          }
        },
        "ce30792bbd814748810e781815ea4d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0d7af7f2c414c0f96b9d67de841e7a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e212715ef00a41fbb64dcbd5c97d69a9"
          }
        },
        "c6c3dbb6290b42e2b4f9d2ea3437146a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_daf211e82f114b3b8e04d559e7912b94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 613B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99f0f3a45a744f21beb52212f5fc2b33"
          }
        },
        "c2b781f13ee54fa7b9923d733f44a5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d49bca4c481d473dbcad54ef4776f716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d7af7f2c414c0f96b9d67de841e7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e212715ef00a41fbb64dcbd5c97d69a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daf211e82f114b3b8e04d559e7912b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99f0f3a45a744f21beb52212f5fc2b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e67766f6511e45618ff600cde1ac15c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a998a74a75b43c6a8d7a7e5a10e5631",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64bae68ac37b40c4955dbe70176b93a7",
              "IPY_MODEL_cd8630f8db9f44f2a0cfd5161532dd15",
              "IPY_MODEL_187cc9e86fe440fa8f7b2f9e25f200d3"
            ]
          }
        },
        "4a998a74a75b43c6a8d7a7e5a10e5631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64bae68ac37b40c4955dbe70176b93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_009fde7f0e7d49d393a4ef8201c3c4d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95e0642ca92a4aec9e4616e08524466f"
          }
        },
        "cd8630f8db9f44f2a0cfd5161532dd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07c638e3fcf743f29c30c32a38400366",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9268def9ebb4f00b508b3bb88641725"
          }
        },
        "187cc9e86fe440fa8f7b2f9e25f200d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8d87885d45b480d87fb9a4536672df9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 12.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b26dfa0e3603441eba3bc1d80ecd7609"
          }
        },
        "009fde7f0e7d49d393a4ef8201c3c4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95e0642ca92a4aec9e4616e08524466f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07c638e3fcf743f29c30c32a38400366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9268def9ebb4f00b508b3bb88641725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8d87885d45b480d87fb9a4536672df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b26dfa0e3603441eba3bc1d80ecd7609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c843d51f4be489b8820ab1cd3a8c615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9dd2d3864c644292a8d2ee22354b9356",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd11c0a84ca84e2e8b75480d3751fc9f",
              "IPY_MODEL_f98bb3057dea44fcbc05f9f2bf7e1d53",
              "IPY_MODEL_b2874b437ea54ed69026a9eae8896043"
            ]
          }
        },
        "9dd2d3864c644292a8d2ee22354b9356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd11c0a84ca84e2e8b75480d3751fc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0557c17de035415a97cdbfae6c2c9d01",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef969ea542644635a08d09bf4519e08d"
          }
        },
        "f98bb3057dea44fcbc05f9f2bf7e1d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0faa3517532e419c8852292b9821389f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebbe0b5463d44864a8514d176c4cb1e9"
          }
        },
        "b2874b437ea54ed69026a9eae8896043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_357e69d7c489404f8ceb2249aebce64f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 369kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f095abe52c144a1c8213c7fa686e51bb"
          }
        },
        "0557c17de035415a97cdbfae6c2c9d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef969ea542644635a08d09bf4519e08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0faa3517532e419c8852292b9821389f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebbe0b5463d44864a8514d176c4cb1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "357e69d7c489404f8ceb2249aebce64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f095abe52c144a1c8213c7fa686e51bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5841495bb5348d8b15e61722e2270d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9afc9ed18c4a4325be6d1a1bd981e89c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3ca1ab1e996435d8e3fa1d305d59039",
              "IPY_MODEL_7edd90c0feb94c43b591e01b4e2d8bb8",
              "IPY_MODEL_9256b477240c4ab780271f0bd3962fe2"
            ]
          }
        },
        "9afc9ed18c4a4325be6d1a1bd981e89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3ca1ab1e996435d8e3fa1d305d59039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb0b6fe4824849848cb12b4df7143460",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4c6954f0d4d428f8193300322f9bf30"
          }
        },
        "7edd90c0feb94c43b591e01b4e2d8bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ba2ccf10f4f4202a82f5f3fdfa4106b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f543dc8e2c864382aa3c9d10c97a13bd"
          }
        },
        "9256b477240c4ab780271f0bd3962fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f46aad0dd96e4ce6a5f2b27e099282b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 695kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f82a386fa7824beeba9a813bf3f5ebc8"
          }
        },
        "cb0b6fe4824849848cb12b4df7143460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4c6954f0d4d428f8193300322f9bf30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ba2ccf10f4f4202a82f5f3fdfa4106b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f543dc8e2c864382aa3c9d10c97a13bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f46aad0dd96e4ce6a5f2b27e099282b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f82a386fa7824beeba9a813bf3f5ebc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1df3f647c69d4c239904d7cc689c5614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_62d61fc06c3046da9457029429d4874d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_021e2655d2b84534b0789503963fe156",
              "IPY_MODEL_d81d7f5a79744667a2febc8181f21159",
              "IPY_MODEL_ca5f1013242e4d9ab3afa294f53951ad"
            ]
          }
        },
        "62d61fc06c3046da9457029429d4874d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "021e2655d2b84534b0789503963fe156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_830589d3a12e405cbe6fc0ac4b265640",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3e9eb5c46d0408398de551d8e8d5e8b"
          }
        },
        "d81d7f5a79744667a2febc8181f21159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c00ef74462f4e69a77b560a6954cd5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c3adc1329844803a23d7f6527128b31"
          }
        },
        "ca5f1013242e4d9ab3afa294f53951ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_531dda8acbd341c3a7bac83cdd850bfb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 16.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e70d29f4d4642e788b4bb8f4d6d6a1a"
          }
        },
        "830589d3a12e405cbe6fc0ac4b265640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3e9eb5c46d0408398de551d8e8d5e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c00ef74462f4e69a77b560a6954cd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c3adc1329844803a23d7f6527128b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531dda8acbd341c3a7bac83cdd850bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e70d29f4d4642e788b4bb8f4d6d6a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac4b4450a5ee48839f7059f266e5d4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2e36e9dfb6344ccaef0d8a001daf456",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7fd3152a6544ae1996bfded3c1fccf6",
              "IPY_MODEL_fe9b40f709c349af81903752b912515e",
              "IPY_MODEL_2ff92c818c90405895a70d879f6317ac"
            ]
          }
        },
        "a2e36e9dfb6344ccaef0d8a001daf456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7fd3152a6544ae1996bfded3c1fccf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c5d3b0f5003499f80b6ec63df104e77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b6d871bdac04fc593deedfd31f80364"
          }
        },
        "fe9b40f709c349af81903752b912515e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ffd77c7da504d24a8c9afac84757d54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff5c8a263914498b8dd885b277a44aee"
          }
        },
        "2ff92c818c90405895a70d879f6317ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61665225602b402db60d93a820b22a58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:08&lt;00:00, 53.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e986ab17df6f4237938c1ae90cc47d6b"
          }
        },
        "4c5d3b0f5003499f80b6ec63df104e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b6d871bdac04fc593deedfd31f80364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ffd77c7da504d24a8c9afac84757d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff5c8a263914498b8dd885b277a44aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61665225602b402db60d93a820b22a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e986ab17df6f4237938c1ae90cc47d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzu3ED7m8z2G"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KYuW1Mo8u3w",
        "outputId": "ce9f9606-b116-44ab-b552-355362ec9327"
      },
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare --upgrade\n",
        "!pip install transformers\n",
        "!pip install -q tf-models-official\n",
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aimodelshare in /usr/local/lib/python3.7/dist-packages (0.0.49)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.10.0+cu111)\n",
            "Requirement already satisfied: Pympler==0.9 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (0.9)\n",
            "Requirement already satisfied: onnxruntime>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.9.0)\n",
            "Requirement already satisfied: keras2onnx>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.7.0)\n",
            "Requirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (0.11.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (0.90)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.8.1)\n",
            "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (2.7.0)\n",
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (3.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.6.3)\n",
            "Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (0.24.2)\n",
            "Requirement already satisfied: PyJWT==2.2.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (2.2.0)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.9.3)\n",
            "Requirement already satisfied: onnxmltools>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.10.0)\n",
            "Requirement already satisfied: onnx>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.10.2)\n",
            "Requirement already satisfied: botocore==1.21.2 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.21.2)\n",
            "Requirement already satisfied: boto3==1.18.2 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.18.2)\n",
            "Requirement already satisfied: docker==5.0.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (5.0.0)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.25.11)\n",
            "Requirement already satisfied: skl2onnx>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from aimodelshare) (1.10.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->aimodelshare) (0.37.0)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->aimodelshare) (1.15.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3==1.18.2->aimodelshare) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3==1.18.2->aimodelshare) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.21.2->aimodelshare) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker==5.0.0->aimodelshare) (1.2.1)\n",
            "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.7/dist-packages (from docker==5.0.0->aimodelshare) (2.23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->aimodelshare) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->aimodelshare) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->aimodelshare) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->aimodelshare) (1.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from keras2onnx>=1.7.0->aimodelshare) (3.17.3)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from keras2onnx>=1.7.0->aimodelshare) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.9.0->aimodelshare) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.7.0->aimodelshare) (1.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (2.10)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn>=0.11.2->aimodelshare) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn>=0.11.2->aimodelshare) (1.1.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn>=0.11.2->aimodelshare) (2018.9)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (12.0.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (0.2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (0.22.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (1.42.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->aimodelshare) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.5.0->aimodelshare) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->aimodelshare) (3.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcpv6VD7AaG3"
      },
      "source": [
        "## for deep learning\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "## for bert language model\n",
        "import transformers"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8pFBIBxRAQu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNGm-luaAjRl"
      },
      "source": [
        "## for data\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "## for processing\n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "import shutil\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl1YNYr_muxw",
        "outputId": "05145d02-1c8d-4efb-9e71-ae4e0d8278b1"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRgjO2kS8yj0"
      },
      "source": [
        "#  Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcYK-ETJgQao",
        "outputId": "99e03742-6540-4513-e841-7805822812fd"
      },
      "source": [
        "## Google Colab- Google Drive connectionsinstructions \n",
        "\n",
        "# This step needs to be done for the first time when you're reading something from the Shared Project Folder \n",
        "# Please navigate to \"Shared with me\" on your Gdrive home sceen\n",
        "# Right click on the \"NLP-Group1-FinalProj\" (the primary folder for this project) and select \"Add shortcut to Drive\"\n",
        "# This way the below code can find a link to the Project drive folder through your own drive.\n",
        "\n",
        "\n",
        "# Mounting your personal Gdrive to the Colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BSoT8GLgVuB"
      },
      "source": [
        "# Reading the dataframe to Data folder as a csv\n",
        "imdb_data = pd.read_csv('/content/drive/My Drive/NLP-Group1-FinalProj/Data/imdb.csv', sep=',')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzHVysJ6h53z"
      },
      "source": [
        "#pos_neg_encoding = {'positive': 1, 'negative': 0}\n",
        "\n",
        "# The values 10 and 20 are replaced by 'A' and 'B'\n",
        "#imdb_data['sentiment'].replace(pos_neg_encoding, inplace=True)\n",
        "\n",
        "# Creating two variables X and y for respective columns and attributes\n",
        "y_train_labels = imdb_data['sentiment'].squeeze()\n",
        "y = [1 if label =='positive' else 0 for label in y_train_labels]\n",
        "X = imdb_data.loc[:, imdb_data.columns != 'sentiment'].squeeze()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCZ_V1iRsYgr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into train-test datasets - Default .75/.25 split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt8ZgPkS9CQi"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YgKHRf29Bfi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "70e2c68cbaf040ed83605cf54f6c26dc",
            "3b0c75620a3d4a758b69a3694e906b34",
            "5cafb691fbb44af9b09521f617c7e903",
            "ce30792bbd814748810e781815ea4d9c",
            "c6c3dbb6290b42e2b4f9d2ea3437146a",
            "c2b781f13ee54fa7b9923d733f44a5da",
            "d49bca4c481d473dbcad54ef4776f716",
            "d0d7af7f2c414c0f96b9d67de841e7a0",
            "e212715ef00a41fbb64dcbd5c97d69a9",
            "daf211e82f114b3b8e04d559e7912b94",
            "99f0f3a45a744f21beb52212f5fc2b33",
            "e67766f6511e45618ff600cde1ac15c3",
            "4a998a74a75b43c6a8d7a7e5a10e5631",
            "64bae68ac37b40c4955dbe70176b93a7",
            "cd8630f8db9f44f2a0cfd5161532dd15",
            "187cc9e86fe440fa8f7b2f9e25f200d3",
            "009fde7f0e7d49d393a4ef8201c3c4d5",
            "95e0642ca92a4aec9e4616e08524466f",
            "07c638e3fcf743f29c30c32a38400366",
            "f9268def9ebb4f00b508b3bb88641725",
            "a8d87885d45b480d87fb9a4536672df9",
            "b26dfa0e3603441eba3bc1d80ecd7609",
            "9c843d51f4be489b8820ab1cd3a8c615",
            "9dd2d3864c644292a8d2ee22354b9356",
            "bd11c0a84ca84e2e8b75480d3751fc9f",
            "f98bb3057dea44fcbc05f9f2bf7e1d53",
            "b2874b437ea54ed69026a9eae8896043",
            "0557c17de035415a97cdbfae6c2c9d01",
            "ef969ea542644635a08d09bf4519e08d",
            "0faa3517532e419c8852292b9821389f",
            "ebbe0b5463d44864a8514d176c4cb1e9",
            "357e69d7c489404f8ceb2249aebce64f",
            "f095abe52c144a1c8213c7fa686e51bb",
            "e5841495bb5348d8b15e61722e2270d8",
            "9afc9ed18c4a4325be6d1a1bd981e89c",
            "d3ca1ab1e996435d8e3fa1d305d59039",
            "7edd90c0feb94c43b591e01b4e2d8bb8",
            "9256b477240c4ab780271f0bd3962fe2",
            "cb0b6fe4824849848cb12b4df7143460",
            "b4c6954f0d4d428f8193300322f9bf30",
            "2ba2ccf10f4f4202a82f5f3fdfa4106b",
            "f543dc8e2c864382aa3c9d10c97a13bd",
            "f46aad0dd96e4ce6a5f2b27e099282b5",
            "f82a386fa7824beeba9a813bf3f5ebc8"
          ]
        },
        "outputId": "a5304659-ba73-4729-a2ec-76869d82760e"
      },
      "source": [
        "## distil-bert tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e2c68cbaf040ed83605cf54f6c26dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e67766f6511e45618ff600cde1ac15c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c843d51f4be489b8820ab1cd3a8c615",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5841495bb5348d8b15e61722e2270d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFPcaMtEiuDT"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'@([a-zA-Z0-9_]{1,50})', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', ' ', text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7fGy1kDicdj"
      },
      "source": [
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_ITiptHiQud",
        "outputId": "27a2484c-2515-47df-b4a7-cf1dd83425c3"
      },
      "source": [
        "# Concatenate train data and test data\n",
        "all_reviews = np.concatenate([X_train.values, X_val.values])\n",
        "# Encode our concatenated data\n",
        "encoded_reviews = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_reviews]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_reviews])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  3157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTnALh3_mMMm",
        "outputId": "2145df8b-34e2-4aa3-a31d-8aa65e95ad83"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert(X_train[[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X_train[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "Token IDs:  [101, 2028, 1997, 1996, 2060, 15814, 2038, 3855, 2008, 2044, 3666, 2074, 1015, 11472, 2792, 2017, 1005, 2222, 2022, 13322, 1012, 2027, 2024, 2157, 1010, 2004, 2023, 2003, 3599, 2054, 3047, 2007, 2033, 1012, 1996, 2034, 2518, 2008, 4930, 2033, 2055, 11472, 2001, 2049, 24083, 1998, 4895, 10258, 2378, 8450, 5019, 1997, 4808, 1010, 2029, 2275, 1999, 2157, 2013, 1996, 2773, 2175, 1012, 102]\n",
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1najWVa4XNe-"
      },
      "source": [
        "# Model Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo9r3wlQ-e0Z"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "1df3f647c69d4c239904d7cc689c5614",
            "62d61fc06c3046da9457029429d4874d",
            "021e2655d2b84534b0789503963fe156",
            "d81d7f5a79744667a2febc8181f21159",
            "ca5f1013242e4d9ab3afa294f53951ad",
            "830589d3a12e405cbe6fc0ac4b265640",
            "f3e9eb5c46d0408398de551d8e8d5e8b",
            "6c00ef74462f4e69a77b560a6954cd5b",
            "3c3adc1329844803a23d7f6527128b31",
            "531dda8acbd341c3a7bac83cdd850bfb",
            "7e70d29f4d4642e788b4bb8f4d6d6a1a",
            "ac4b4450a5ee48839f7059f266e5d4ed",
            "a2e36e9dfb6344ccaef0d8a001daf456",
            "e7fd3152a6544ae1996bfded3c1fccf6",
            "fe9b40f709c349af81903752b912515e",
            "2ff92c818c90405895a70d879f6317ac",
            "4c5d3b0f5003499f80b6ec63df104e77",
            "1b6d871bdac04fc593deedfd31f80364",
            "8ffd77c7da504d24a8c9afac84757d54",
            "ff5c8a263914498b8dd885b277a44aee",
            "61665225602b402db60d93a820b22a58",
            "e986ab17df6f4237938c1ae90cc47d6b"
          ]
        },
        "id": "LCUcli7jqEJU",
        "outputId": "03cca6d3-77cb-40b6-943e-12756fca970a"
      },
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "#class BertClassifier(nn.Module):\n",
        "\"\"\"Bert Model for Classification Tasks.\n",
        "\"\"\"\n",
        "#def __init__(self, freeze_bert=False):\n",
        "\"\"\"\n",
        "@param    bert: a BertModel object\n",
        "@param    classifier: a torch.nn.Module classifier\n",
        "@param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "\"\"\"\n",
        "#super\n",
        "#super(BertClassifier, self).__init__()\n",
        "# Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "freeze_bert=False\n",
        "D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "# Instantiate BERT model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Instantiate an one-layer feed-forward classifier\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(D_in, H),\n",
        "    nn.ReLU(),\n",
        "    #nn.Dropout(0.5),\n",
        "    nn.Linear(H, D_out))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1df3f647c69d4c239904d7cc689c5614",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac4b4450a5ee48839f7059f266e5d4ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.61 s, sys: 1.76 s, total: 10.4 s\n",
            "Wall time: 12.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yX0PoAEOXl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce940f8-4e61-4537-a856-dd2a22f5725e"
      },
      "source": [
        "bert.parameters()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f9b84a57ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH-Ql3LEL4jh"
      },
      "source": [
        "\n",
        "# Freeze the BERT model\n",
        "if freeze_bert:\n",
        "    for param in bert.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "def forward(self, input_ids, attention_mask):\n",
        "    \"\"\"\n",
        "    Feed input to BERT and the classifier to compute logits.\n",
        "    @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                  max_length)\n",
        "    @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                  information with shape (batch_size, max_length)\n",
        "    @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                  num_labels)\n",
        "    \"\"\"\n",
        "    # Feed input to BERT\n",
        "    outputs = self.bert(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask)\n",
        "    \n",
        "    # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "    last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "    # Feed input to classifier to compute logits\n",
        "    logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "s426baRlMHoZ",
        "outputId": "31811371-ceb2-4b1f-a2ad-a95c80e0ab78"
      },
      "source": [
        "# Instantiate Bert Classifier\n",
        "bert_classifier = classifier(freeze_bert=False)\n",
        "\n",
        "# Tell PyTorch to run the model on GPU\n",
        "bert_classifier.to(device)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = AdamW(bert_classifier.parameters(),\n",
        "                  lr=5e-5,    # Default learning rate\n",
        "                  eps=1e-8    # Default epsilon value\n",
        "                  )\n",
        "\n",
        "# Total number of training steps\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Set up the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0, # Default value\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6004b8de3aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate Bert Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreeze_bert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tell PyTorch to run the model on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'freeze_bert'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzbaEVWvqWwQ"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNTcx3__qYtg"
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eez5l0OFqi6P"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=3)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=3, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQULARd1WMy"
      },
      "source": [
        "# Predict and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnBpyqSVqrzw"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDRmSmRh1UK6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "59A56UNjqsjG",
        "outputId": "d5f4d6b4-7995-4e88-ee3b-0633a713f78d"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: nan\n",
            "Accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvf3wQlFqv6e"
      },
      "source": [
        "# # Concatenate the train set and the validation set\n",
        "# full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
        "# full_train_sampler = RandomSampler(full_train_data)\n",
        "# full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# # Train the Bert Classifier on the entire training data\n",
        "# set_seed(42)\n",
        "# bert_classifier, optimizer, scheduler = initialize_model(epochs=3)\n",
        "# train(bert_classifier, full_train_dataloader, epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f93gae9wUY1"
      },
      "source": [
        "# # Compute predicted probabilities on the test set\n",
        "# probs = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "# # Evaluate the Bert classifier\n",
        "# evaluate_roc(probs, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz-gV6-o-j9n"
      },
      "source": [
        "# Model saving ONXX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "OF42fHFMI26g",
        "outputId": "d3143519-b24e-4f52-9ff3-ea3adeb71e91"
      },
      "source": [
        "bert_classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-ec896557c34f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BertClassifier' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQobDxyutxpE",
        "outputId": "2b933a36-a4f8-47bc-a2c4-3d20cb5982a3"
      },
      "source": [
        "\n",
        "export_dir='./imdb_trained_bert'\n",
        "tf.saved_model.save(bert_classifier, export_dir=saved_model_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-a8fbd2b4f1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./imdb_trained_bert'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1278\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1315\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1316\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1317\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1414\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1416\u001b[0;31m         \u001b[0;34m\"Expected an object of type `Trackable`, such as `tf.Module` or a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m         \u001b[0;34mf\"subclass of the `Trackable` class, for export. Got {obj} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         f\"with type {type(obj)}.\")\n",
            "\u001b[0;31mValueError\u001b[0m: Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=768, out_features=50, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=50, out_features=2, bias=True)\n  )\n) with type <class '__main__.BertClassifier'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hry1FGez-uo5"
      },
      "source": [
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCu0jzgbH6hN"
      },
      "source": [
        "tf.saved_model.save(bert_classifier, export_dir=export_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWquOV7-aNs"
      },
      "source": [
        "# '''\n",
        "# Define arguments to pass to onnx exporter\n",
        "# '''\n",
        "# model_onnx_path = \"bert_classifier_model.onnx\"\n",
        "# model = BertClassifier()\n",
        "\n",
        "# # The inputs \"input_ids\", \"token_type_ids\" and \"attention_mask\" are torch tensors of shape batch*seq_len\n",
        "# dummy_input = (b_input_ids, b_attn_mask)\n",
        "# input_names = [\"input_ids\", \"attention_mask\"]\n",
        "# output_names = outputs = BertClassifier().bert(input_ids=b_input_ids, attention_mask=b_attn_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bV2YpJ7AG_O"
      },
      "source": [
        "# '''\n",
        "# convert model to onnx\n",
        "# '''\n",
        "# torch.onnx.export(model, dummy_input, model_onnx_path,input_names = input_names, output_names = output_names, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdNgYuxywhQv"
      },
      "source": [
        "#Model Submission AIMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSZ-bS_SJhlP",
        "outputId": "1cc876bc-3a9c-464a-9740-8a323e4df643"
      },
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl='https://q29m0ncx23.execute-api.us-east-1.amazonaws.com/prod/m' #This is the unique rest api that powers this Covid Tweet Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLCr85yWJjZ6"
      },
      "source": [
        "#Instantiate Competition\n",
        "import aimodelshare as ai\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "zgpaNqd6JlfW",
        "outputId": "61a520d7-1af6-4cbe-d0ea-73ed525fc47c"
      },
      "source": [
        "# #Submit Model 1: \n",
        "\n",
        "# #-- Generate predicted y values (Model 1)\n",
        "# #Note: Keras predict returns the predicted column index location for classification models\n",
        "# prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# # extract correct prediction labels \n",
        "# prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(\n",
        "                                 prediction_submission=preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-eafee806cd8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Submit Model 1 to Competition Leaderboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m mycompetition.submit_model(\n\u001b[0;32m---> 12\u001b[0;31m                                  prediction_submission=preds)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: submit_model() missing 2 required positional arguments: 'model_filepath' and 'preprocessor_filepath'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "hUciqVSa-mUZ",
        "outputId": "aa3b17e1-32f7-4962-ba5a-000c6f6ca9cf"
      },
      "source": [
        "# Save sklearn model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(BertModel, framework='pytorch',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-8ab95d21e16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m onnx_model = model_to_onnx(BertModel, framework='pytorch',\n\u001b[1;32m      5\u001b[0m                           \u001b[0mtransfer_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                           deep_learning=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aimodelshare/aimsonnx.py\u001b[0m in \u001b[0;36mmodel_to_onnx\u001b[0;34m(model, framework, model_input, initial_types, transfer_learning, deep_learning, task_type, epochs)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0mdeep_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                                 \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                 epochs=epochs)\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aimodelshare/aimsonnx.py\u001b[0m in \u001b[0;36m_pytorch_to_onnx\u001b[0;34m(model, model_input, transfer_learning, deep_learning, task_type, epochs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;31m# generate onnx file and save it to temporary path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# load onnx file from temporary path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    318\u001b[0m                         \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0m_set_opset_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0m_set_operator_export_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m             val_keep_init_as_ip = _decide_keep_init_as_input(keep_initializers_as_inputs,\n\u001b[1;32m    711\u001b[0m                                                              \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mselect_model_mode_for_export\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mis_originally_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'BertModel' has no attribute 'training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBhox-LLHU0K",
        "outputId": "3b563d4b-fc1f-466c-bb0b-455e2e68ac99"
      },
      "source": [
        "optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.999)\n",
              "    correct_bias: True\n",
              "    eps: 1e-08\n",
              "    initial_lr: 5e-05\n",
              "    lr: 0.0\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "4BM6BRlSGhgF",
        "outputId": "1b0ec4df-f701-4841-eaff-25d16f4289e0"
      },
      "source": [
        "model_to_onnx( bert_classifier, framework='pytorch',deep_learning=True)\n",
        "#model_to_onnx()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:363: UserWarning: Skipping _decide_input_format\n",
            " 'NoneType' object is not subscriptable\n",
            "  warnings.warn(\"Skipping _decide_input_format\\n {}\".format(e.args[0]))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-2d21be4941e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model_to_onnx()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aimodelshare/aimsonnx.py\u001b[0m in \u001b[0;36mmodel_to_onnx\u001b[0;34m(model, framework, model_input, initial_types, transfer_learning, deep_learning, task_type, epochs)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0mdeep_learning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                                 \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                 epochs=epochs)\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aimodelshare/aimsonnx.py\u001b[0m in \u001b[0;36m_pytorch_to_onnx\u001b[0;34m(model, model_input, transfer_learning, deep_learning, task_type, epochs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;31m# generate onnx file and save it to temporary path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# load onnx file from temporary path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    318\u001b[0m                         \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             custom_opsets=custom_opsets, use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0m_create_interpreter_name_lookup_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'attention_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ-iMzXX-t8D",
        "outputId": "7d993ac3-b989-459d-9416-8a0063246e93"
      },
      "source": [
        "type(bert_classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.BertClassifier"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AekEmddOqzDU"
      },
      "source": [
        "# Prediction on Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4gDvNPW5Y5A"
      },
      "source": [
        "groc_data = pd.read_csv('/content/drive/My Drive/NLP-Group1-FinalProj/Data/Raw/groc_amz_rev.csv.gz', sep=',', compression=\"gzip\")\n",
        "groc_data = groc_data.head(10000)\n",
        "\n",
        "star_revs = groc_data.loc[groc_data.rating==1]\n",
        "groc_data = groc_data['review_text'].squeeze()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuCmJ52AXqfG"
      },
      "source": [
        "#star_revs = groc_data.loc[groc_data.rating==1]\n",
        "star_revs = star_revs['review_text'].squeeze()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7fsNrAiAYKL7",
        "outputId": "85a70e7f-e8ae-46a1-980a-617244ca2874"
      },
      "source": [
        "star_revs[5]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Don't buy this item - rip off at this price.  My bad, my mistake.  Pay attention to the quantity and don't pay more than $4-5 per bottle\""
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "cKfm_J7jVsR6",
        "outputId": "d4d5e7c7-b626-40fa-a305-bee32e473fd2"
      },
      "source": [
        "groc_data[197]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"These are a great treat but too expensive. I'll get them from time to time because I like them so much (especially frozen), but not too often because of the price. They aren't too sweet and not too bitter. They are just right for my personal taste.\""
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hW8TmUcVrfa"
      },
      "source": [
        "examples = [\n",
        "    'I bought it for my girlfriend. The taste feeling of this chocolate is fancy. My girlfriend loves it very much!',  # this is the same sentence tried earlier\n",
        "    'A creamy, good quality kit kat. Tastes mostly like white chocolate with a slight touch of green tea. I would have preferred a slightly more pronounced green tea flavor. Its a very smooth flavor and is less sweeter than traditional kit kats.I shared it with others and the response was neutral. I personally liked it.I ordered mine from SamuraiJapan with standard shipping and received the product in about 2 weeks. Fair enough. The item was well packaged and the chocolates are in excellent condition.',\n",
        "    'I bought it for my 17 year old as she loves kit kat.We bought a mix of available flavours.This was to be the cream of the cake as it was special, but unfortunately it came somewhat crushed and the taste was nothing to write home about...',\n",
        "    'i have to ration these things they are so good, these were not melted like previous bags were. I just wish they weren't so pricey.',\n",
        "    'Dont buy this item - rip off at this price.  My bad, my mistake.  Pay attention to the quantity and dont pay more than $4-5 per bottle'\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "CcjuBRKK6XH0",
        "outputId": "575479ba-ece0-454c-844b-cf48fb96ee10"
      },
      "source": [
        "am_rev_pred_data = text_preprocessing(groc_data.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-07e41f9c8f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mam_rev_pred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-da84b8c30d8b>\u001b[0m in \u001b[0;36mtext_preprocessing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Remove '@name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'@([a-zA-Z0-9_]{1,50})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Replace '&amp;' with '&'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPpPqu3gAOfU",
        "outputId": "6e95d124-8f4d-45e1-ee87-a2c7357a6e93"
      },
      "source": [
        "am_rev_pred_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"No sugar, no GMO garbage, no fillers that come with store bought extracts. This stuff is just amazing. I use it in everything from baking to cooking and even as suggested in my coffee which is saying a lot because I normally do not care for flavored coffee! You cannot go wrong with this. I've ordered from this merchant before, customer satisfaction is their priority and service was quick, shipped right out with tracking even! I'll be buying from GLS Goods again! I won't use any other vanilla!\",\n",
              "       \"This is my absolute, undisputed favorite tea right now. I love Darjeeling, but I'm not wildly fond of the lighter, first flush ones for being too delicate. This Darjeeling, especially when steeped a while, has a good tannic bite. It's bright and warm all at the same time, and pretty much explodes with that classic 'Darjeeling' flavor. It's not even remotely delicate, but neither is it hard-edged. It's sort of like good-looking men in bespoke suits -- strong but refined. I use boiling water, steep for 4-5 minutes, and with a large mug use one Splenda and just a tiny splash of milk. Then get out of my way, because with this tea, I can take on the world!\",\n",
              "       'I ordered spongbob slippers and I got John Cena not too happy ... my son was looking forward to them being spongebob!! ..  there very thin :(((( ps if I wanted john cena I would have ordered that ... zero stars',\n",
              "       ...,\n",
              "       'Love this item. Bought it in mexico for 98 cents. Ad said it was 5 oz. Turned out it was 1 oz. Not worth what I paidfor it.',\n",
              "       \"I love this sauce.  This sauce is made to showcase Guajillo peppers, and it does so very well.  If you are not familiar with Guajillo's, they are similar to Ancho's but with a more chocolatey flavor.It is my favorite in the Bufalo line, and is the original sauce that started it all for that company.  Very highly recommended.\",\n",
              "       \"This sauce is the best ever It  tastes so freaking deliciou. If your a person that doesn't like really hot stuff don't worry this is not spicy. Once you Try this sauce it will instantly be your favorite, its been mine since I tried it in the mid 90s\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSImRmj_8tGn",
        "outputId": "72b3516e-6e11-465f-ad0b-32ea006ae6bd"
      },
      "source": [
        "all_reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Dogtown and Z-Boys<br /><br />Summary: Dogtown and Z-boys is a documentary about a group of revolutionary teenagers that changed the world of surfing and skateboarding in Venice (Dogtown), California as we know it today. With their low pivotal style, they embarked on a Larry Bertlemen influenced journey that would lead to countless successes and a couple failures. After the Dogtown articles were featured in a reinstated Skateboarder Magazine, the sport was revamped and the members of the Zephyr skateboard team forgot about Jeff Ho, and looked to be on summer vacation for the rest of their lives by joining other skateboard teams that could afford to pay them like movie stars. The original Zephyr Skateboard Team put together by Jeff Ho (Zephyr Surfshop Owner) and Craig Stecyk (Photographer) included Jay Adams, Tony Alva, Stacy Peralta, Bob Biniak, Chris Cahill, Shogo Kubo, Paul Constantineau, Jim Muir, Peggy Oki (the only female), Nathan Pratt, Wentzle Ruml IV, Allen Sarlo, and David Ray Perry. All of the original members except Jay Adams and Chris Cahill are still well and surfing/skating. Jay Adams, at the time of the documentary, was serving time on drug related charges. Chris Cahill, at the time of the documentary, was last seen in Mexico.<br /><br />Themes: The themes of this documentary are kind of read-between-the-lines, but if there were a clear-cut theme it would be that even kids can spark revolutions. Other themes would include extensive partying in one\\'s past may lead to an unfulfilling future, and by planning and being careful with one\\'s assets a very rewarding future could be at hand.<br /><br />Other Works: Stacy Peralta (Writer and Director) has a fairly wide range of documentaries that he has either written, produced, or directed. Most with a common theme of surfing or skateboarding, such as Riding Giants, Sk8 TV, The Bones Brigrades, and Lords of Dogtown. He has also done films with a theme of growing up in America as a teenager, films such as: Influences: From Yesterday to Today, Crips and Bloods: Made in America, and The 70s: The Decade that Changed Television.<br /><br />Subjects: The subjects of Dogtown and Z-boys are the original members of the Zephyr Skateboard Team excluding Chris Cahill. Peralta included Jeff Ho and Craig Stecyk in the interviews. Other subjects were people who grew up during the 70s reading the Dogtown Articles as well as skateboard enthusiasts. Skaters from the Dogtown area, but not on the team were interviewed.<br /><br />Editing: The editing of this film was phenomenal in my opinion. There were scenes of the subjects talking so that the audience could see who was speaking and get a sense of the character, but would immediately cutaway to archival footage that would explain what the speaker was saying. When a song could explain the emotions of the subjects better, such as when Jay Adams\\' unfortunate life was a subject of talk, the song Old Man by Neil Young was played, which evokes many emotions. Sean Penn was the narrator for the film and he explained the transitions throughout the film. The film was presented chronologically from the time the Zephyr surf team was put together, to creating the skateboard team, to all of the Z-boys leaving the team to join other skate companies or create their own company. <br /><br />Cinematography: The film was shot in an interesting way. The film of the subjects speaking were all in black and white and all of the archival footage of the Z-Boys surfing or skating were in color. Of course the footage from the 70s was grainy, but that only enhanced the film. The interviewees were mostly shot in the same area it appears, but all were outside. All of the footage was very well-controlled even the archival footage which I found very surprising. <br /><br />Music: \"Seasons of Wither\"-Performed by Aerosmith \"Toys in the Attic\"-Performed by Aerosmith \"Generation Landslide\"- Alice Cooper \"One Way Out\"- Performed by The Allman Brothers \"Lollipops and Roses\" and \"Whipped Cream\"-performed by Herb Alpert \"Into the Void\" and \"Paranoid\"- performed by Black Sabbath \"Godzilla\"- Blue Oyster Cult \"Aladdin Sane\" and \"Rebel Rebel\"- David Bowie \"Fastcars\"- The Buzzcocks \"Gut Feeling\"- Devo \"I\\'ll Give you Money\"- Peter Frampton \"Funk 49\"- James Gang \"Ezy Rider\" and \"Foxy Lady\" and \"Freedom\" and \"Bold as Love\"- Jimi Hendrix \"Sidewalk Surfing\"- Jan and Dean \"Achilles Last Stand\" and \"Hot on for Nowhere\"- Led Zeppelin \"Six Underground\"- The Sneaker Pimps \"Surfrider\"- The Lively Ones \"Cat Scratch Fever\" and \"Motor City Madhouse\" and \"Wang Dang Sweet Poontang- Ted Nugent \"Us and Them\"- Pink Floyd \"Bad Boys\"- The Pretenders \"Maggie May\"- Rod Stewart \"I Wanna be Your Dog\" and \"Gimme Danger\"- The Stooges \"Children of the Revolution\"- T-Rex \"Bad Reputation\"- Thin Lizzy \"Disco Inferno\"- The Tramps \"Hannah\"- Rob Trower \"Rocky Mountain Way\"- Joe Walsh \"Old Man\"- Neil Young \"La Grange\"- ZZ Top<br /><br />The music in the film make the movie. Every one of these songs contributes to what the subjects are saying and evoke emotions that would not have been called to mind otherwise.',\n",
              "       'Alejandro Amenabar, the young and talented Spanish director, clearly shows us he is a serious film maker. Anyone doubting it, should have a look at his latest film \"The Sea Inside\". This is a movie that has been rewarded with numerous accolades, not only in Spain, but throughout the world, wherever this wonderful movie has been shown.<br /><br />If you have not seen the film, perhaps you would like to stop here.<br /><br />Ramon Sampedro is a man confined to bed. Being quadriplegic, he depends on the kindness of strangers for everything. Since his accident, Ramon only thinks in one thing alone: how to end his life! This is the moral issue at the center of the story, based on the real Ramon Sampedro\\'s life.<br /><br />Mr. Amenabar tells the story from Ramon\\'s point of view. There is nothing here that is false or manipulative on his part. After all, he relies on facts that were well known in his country as this case became a \"cause celebre\" in favor of euthanasia, a theme that no one in that country wanted to deal with in Spain.<br /><br />With its background of being a predominantly Roman Catholic country, Spain has evolved into one of the most democratic societies in Europe, a distinction that is more notable because of its long years dominated by a dictator. Yet, in spite of the advances in that society, the idea of taking one\\'s own life, is something not clearly understood by the majority of its citizens, who still considered this subject as something that could not be done in their country.<br /><br />Ramon Sampedro was a man that loved life. He lived an intense life as a young man when he enlisted as a sailor to discover the world. Having no money, this was the only way for him to see other lands, experience other cultures. Ramon\\'s love affair with the sea, is something that people in Galicia learn to love from their childhood. Imagine how that same friendly sea is the one that takes away Ramon\\'s life, as he knew it! In a second, Ramon goes from a vibrant young man into a vegetable!<br /><br />Ramon\\'s family is shattered by the experience. Suddenly they must leave everything aside to take care of him at home. His brother and sister-in-law, are stoic people that deal with the situation as a matter of fact. Their lives become something of an afterthought, because Ramon\\'s life comes first. They tend to the sick man without protesting, or blaming Ramon for the sacrifices they must make to keep him alive.<br /><br />That is why, in their minds, the Sampedros can\\'t comprehend Ramon\\'s wishes to end it all. Haven\\'t they given up having a normal life to take care of him? This moral issue weighs heavily on these uncomplicated and simple people because in their minds, they are doing what came naturally.<br /><br />The second subject of the movie is the legal issue of the euthanasia and the well meaning people that suddenly enter Ramon\\'s life in their desire to help him put an end to his suffering. There\\'s Julia, the lawyer who is herself handicapped and suffers from a rare malady. There is Rosa, the fish cannery worker who becomes infatuated with Ramon. <br /><br />Javier Bardem, makes a brilliant Ramon Sampedro. His transformation is total. We don\\'t doubt from one moment he is no one else but the paralyzed man on that bed. Mr. Bardem can only use his face in order to convey all the emotions trapped inside Ramon. Mr. Bardem makes this man real. This is perhaps Javier Bardem\\'s best role of his career. He surpasses his own award winning performance as Reynaldo Arenas, the late Cuban poet he portrayed in \"Before Night Falls\". <br /><br />In the supporting roles, Belen Rueda, makes an impressive appearance as Julia, the woman fighting her own physical problems. Lola Duenas is also effective as Rosa, the kindred soul that loves Ramon deeply. Celso Bugallo, as Ramon\\'s brother shows a man at a crossroads of his own life. Mabel Rivera makes a compassionate Manuela, the sister-in-law that never asks anything of life, but tends to Ramon without questioning why she has to do it, at all.<br /><br />Mr. Amenabar also has composed the haunting music score for the film. He is a man that never cease to surprise. One wonders what his next project will be, but one wishes him success in whatever he might decide to do in the future.',\n",
              "       'The best scene of \"The People Across The Lake\" is the genuinely creepy, nightly opening-scene featuring a house, a murder & a lake. After that, it\\'s pretty much downhill from there on as far as the horror is concerned. A family (mom, dad, sister & younger brother) is fed up with the (mildly) dangerous environment of suburbia, and decides to go and live near the titular lake. From then on, the film features too much lame happy family-related doo-doo near the lake, with occasionally some corpses popping up here and there. The couple of scenes where they discover the bodies, are pretty convincing (in terms of creepiness), but they are in shrill contrast with the rest of the goings-on (featuring just every-day-life stuff of the family settling in). The truth to the matters (the mystery as to who\\'s doing the killing) is learned too soon, leaving only the family unknowing and the viewer yawning during the unexciting finale (featuring a discovery in a basement and running around the house), like if this made-for-TV thing suddenly remembered it was supposed to be a horror film. It\\'s not really badly made; the content & story is just not interesting enough. The only highlight in the cast is Barry Corbin, though his performance/character is just a bit too goofy to be taken serious. Blond cutie Tammy Lauren (the daughter) might be a recognisable face for avid horror junkies too, as she also starred in \"Wishmaster\" (1997), and made-for-TV outings like \"I Saw What You Did\" (1988) & \"The Stepford Children\" (1987). She hasn\\'t got much to do in this film, though. Skippable, but watchable, if anything.',\n",
              "       ...,\n",
              "       'I just found out before writing this review that \"Komodo vs. Cobra\" and another movie called \"Curse of the Komodo\" were both directed by the same guy, Jim Wynorski. That might explain why they are films of nearly identical premises. They both feature a military-governed island, a colonel whose concerned more about covering his tracks than the lives of his employees, people racing to get to a chopper that is conveniently lying in a field somewhere on the island, and giant komodo dragons created through genetic experiments running amok. What differences are there? Well, the intruders on the island are now capitalists wanting to expose the government secret and there\\'s a giant cobra on the island as well, hence the title \"Komodo vs. Cobra\" even though the conflict between the two monsters is hardly relevant to the \\'story.\\' \"Komodo vs. Cobra\" is more or less what you\\'d expect given its title and its channel origin: the Sci-Fi Channel. Although every now and again you will find one that for one reason or another may appeal to you (I liked a movie called \"Komodo\") I hardly doubt this one will.<br /><br />\"Komodo vs. Cobra\" is not only a boring film, but it\\'s also one of the least enthusiastic sci-fi flicks I\\'ve seen in a long time. In some of these movies, there is an air to them that indicates the filmmakers were giving at least a certain level of effort, but I see very little here. That\\'s indicated again by it just being a rehash of \"Curse of the Komodo.\" The CGI for the monsters look as if they came straight out of a second-rate video game, the cinematography and misc en scene is poor, the acting ranges from passable to poor, the action scenes are dull, and then there are some parts that are, frankly put, unforgivably bad. I see a lot movies where a person will shoot a gun many times without reloading and I can deal with this. But in this movie, where Michael Paré takes a single thirty-eight handgun and fires it approximately fifty times nonstop without reloading once\\x85well, at first I laughed, but even then it just became tiring. That would be the \\'action.\\' A monster appears, people scream, Paré fires nonstop without reloading his gun once throughout the entire picture, and somebody gets eaten.<br /><br />\"Komodo vs. Cobra\" is a very bad movie. The only thing in the movie that is worth mentioning in a charitable manner is an actress named Michelle Borth, who is not only very beautiful, but a surprisingly strong performer. Even with the trashy dialogue and lack of enthusiasm in the screenplay she was given, Michelle Borth managed to pull off a surprisingly good performance and it just appalls me that an actress as good as her can get stuck in a film as junky as this. She obviously took it for the paycheck, but it won\\'t boost her career any, I\\'m afraid.',\n",
              "       'This film is available from David Shepard and Kino on the Before Hollywood There Was Fort Lee, NJ, although that is a shortened version with just the \"behind-the-scenes movie sections. I\\'m not sure if Blackhawk Films only had a film print of these parts, or they edited out the other scenes. The original Blackhawk version was retitled A Movie Romance. The complete feature does survive, but the preprint for this version had some nitrate decomposition, and a couple of sections looked bad, so that may be why Blackhawk\\'s version was edited.<br /><br />Directed by Maurice Tourneur, the film has Tourneur playing himself, or more likely a caricature of himself. Supposedly, director Emile Chautard and future director Joseph von Sternberg also can be spotted.<br /><br />Country lass Mary (Doris Kenyon) longs for a romantic man to sweep her off her feet. She dreams of a troubadour that will woo her, but is constantly interrupted by the only available local boy, Johnny Applebloom.<br /><br />Meanwhile, a film company from New York (actually New Jersey) is filming a western in the countryside. Mary sees an Indian (in full headdress) and raises an alarm -- spoiling a scene that the movie company is filming. She is immediately attracted to the dashing film star Kenneth Driscoll (Robert Warwick). He encourages her to leave her home and try to become an actress in the big city.<br /><br />When she arrives at the studio, she discovers that everything about the movies is fake. The doors and walls are just flats that are hastily assembled for the set. That lanky walk of the western hero or the happy skip of the heroine are just acting too. The sets are on a big revolving stage, so the angle of the sun can even be manipulated. The black attendant at the studio signs all the movie stars\\' \"autographed\" photos. The signs on the wall say \"Positively No Smoking\", but everybody smokes anyway. Even the titles of the film (which are illustrated nicely) emphasize everything fake about the movie-making life.<br /><br />Movie star Driscoll is just as disenchanted with the ho-hum of everyday film-making. He makes a temporary split from girlfriend Vivian (June Elvidge) to pursue this \"exciting\" country girl. His plans are dashed when Mary\\'s screen-test is a stinker. We don\\'t get to see the actual film, but only the audience\\'s pained reactions to it.<br /><br />Mary is devastated, but she doesn\\'t want to admit to everyone back home that she was a failure, so she continues to see Driscoll and we she has lunch with him in the studio cafeteria along with other extras dressed as policemen, soldiers, cowboys, etc.<br /><br />Mary decides to stay with Driscoll. At a party with their movie \"friends\", she agrees to marry him although there is not much love between them. Surprisingly, her mother appears, with a cake especially for Mary\\'s birthday. This causes Mary to re-evaluate her future.<br /><br />This film has all kinds of fascinating scenes of studios, movie sets, dressing rooms, editing rooms, etc. If you\\'ve always wondered what went on behind the scenes when a silent film was being made, this movie peeks behind the curtain.',\n",
              "       '\"Gespenster\" Question of to be cool in the German cinema<br /><br />There are not many German films in the last ten years, who have made me so interest. Yes, the problem of the most German films are in this film \"Gespenster\" too. He is on some places to uncooked to be good to see. Special the figure of Toni (Sabine Timento) is too cool. But thats is in German films always so. Everybody must to learns this coolneß - is the realism in this films. Thats difficult to understand. But in this case it makes some sense, because she steals and she lies - she is the kind of girl is better you never love it, because you lose it. Thats not clear for the other girl Nina in this film. She love her - and she would lose her. But Nina lost everything. She will play with soft emotion and a sad feeling. There is no way - but you must take it said Herbert Achterbusch for twenty years. Thats so often the way it goes in German films. Why? Nina (Julia Hummer) is not inside of the laws of society - the is outside - and there she have no chance. This films tries not on every place to gave her a part inside. Thats one of the problems - the stupid break with conventions - the criminal fascination. Throw it all away - and go nowhere! But the actress plays this difficult part very interesting. On the other side - there the parents - who are the pendant to the two girls. The have a car - a hotel suite - the have money and live in world with music of the opera. But the film stand always in some distance to seem. There is no much explaining of them.<br /><br />In the center of this film, there is one scene you will never forget. The two girls got to a casting. And there they should say how they find together. In this scene Toni will lying on. She said a fantastic story-has nothing to do with her. And then Nina will say the truth. She said it in an introversion way. There is no exhibition in it. She looks to the bottom and said what will happened for here. Thats a great moment. In the next scene on the party with pictures in red this feeling is going on- than Toni goes away...<br /><br />Okay, The film will end - in the German way of coolneß - rubbish - here the circle of sadness is closing. But there was a moment - where is happening something else - and this moment was important. He is more than German coolneß - and this moments are rare in the German cinema in this time!'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ZK_FYL1w8jSR",
        "outputId": "0334c351-5ceb-49cf-d79b-1608289b8651"
      },
      "source": [
        "# Encode our concatenated data\n",
        "encoded_reviews = [tokenizer.encode(sent, add_special_tokens=True) for sent in groc_data]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-436a92ccc67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode our concatenated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroc_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-436a92ccc67a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode our concatenated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroc_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         )\n\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2510\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m         )\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "SHGBmk2Y7kwp",
        "outputId": "539e25b8-ee37-4058-ab4c-f9a33c7f9492"
      },
      "source": [
        "# Encode our concatenated data\n",
        "encoded_reviews = [tokenizer.encode(sent, add_special_tokens=True) for sent in groc_data]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_reviews])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-a3ecddfe2503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode our concatenated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroc_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find the maximum length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-a3ecddfe2503>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Encode our concatenated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoded_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroc_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find the maximum length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         )\n\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2510\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m         )\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mis_pretokenized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOaVVtSQ7xvQ"
      },
      "source": [
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_pred_reviews])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "mW7nboQE6Y_T",
        "outputId": "f2f1f614-5ce8-4183-a4de-232610a7f097"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-0c1cdefd54ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "7-J7tAHz13ZL",
        "outputId": "f26aaa97-fe4c-4472-d432-a63a7196218c"
      },
      "source": [
        "\n",
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(pd.DataFrame(X_test).tweet)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-767a55fd8baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Run `preprocessing_for_bert` on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tokenizing data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_for_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create the DataLoader for our test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-f4838f69186b>\u001b[0m in \u001b[0;36mpreprocessing_for_bert\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#    (6) Return a dictionary of outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         encoded_sent = tokenizer.encode_plus(\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Preprocess sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# Add `[CLS]` and `[SEP]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0;31m# Max length to truncate/pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-da84b8c30d8b>\u001b[0m in \u001b[0;36mtext_preprocessing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Remove '@name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'@([a-zA-Z0-9_]{1,50})'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Replace '&amp;' with '&'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTYAQUfm16VI"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.9\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted non-negative: \", preds.sum())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}